{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJpKaj1YGQZF"
      },
      "source": [
        "# Dialect Conversion Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oUXJxeBGY70"
      },
      "source": [
        "convert text between UK and US dialects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn7KN3aDGhUe"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3rPmdS0RC4S",
        "outputId": "7557a74f-3544-4709-af1c-f212f5e57ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.49.0)\n",
            "Requirement already satisfied: datasets in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.3.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.24.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\himan\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (19.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.0.0)\n",
            "Collecting requests (from transformers)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: xxhash in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\himan\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: colorama in c:\\users\\himan\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Installing collected packages: requests\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "Successfully installed requests-2.32.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "neo-api-client 1.2.0 requires requests==2.25.1, but you have requests 2.32.3 which is incompatible.\n",
            "tensorflow-intel 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.2 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ex_Z4yNGmfE"
      },
      "source": [
        "* Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b-vCUhs5G6_C"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UHbpnHnlHTNd",
        "outputId": "ace93587-7827-4431-812f-68dfd7a1d64f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I CoLoUr 🎨 the centre of my favourite book.</td>\n",
              "      <td>I color the center of my favorite book.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>He is travelling ✈️ to the THEATRE.</td>\n",
              "      <td>He is traveling to the theater.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I have a flat near the lift.</td>\n",
              "      <td>I have an apartment near the elevator.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I have a flat near the lift.</td>\n",
              "      <td>I have an apartment near the elevator.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The PROGRAMME 🗓️ will start at 6 O'CLOCK.</td>\n",
              "      <td>The program will start at 6 o'clock.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>The theatre's performance was breathtaking.</td>\n",
              "      <td>The theater's performance was breathtaking.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>Her behaviour has been commendable.</td>\n",
              "      <td>Her behavior has been commendable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>The cheque was never received.</td>\n",
              "      <td>The check was never received.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>The aeroplane ✈️ took off on time.</td>\n",
              "      <td>The airplane took off on time.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>She wears jewellery for special occasions.</td>\n",
              "      <td>She wears jewelry for special occasions.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     input_text   \n",
              "0   I CoLoUr 🎨 the centre of my favourite book.  \\\n",
              "1           He is travelling ✈️ to the THEATRE.   \n",
              "2                  I have a flat near the lift.   \n",
              "3                 I have a flat near the lift.    \n",
              "4     The PROGRAMME 🗓️ will start at 6 O'CLOCK.   \n",
              "..                                          ...   \n",
              "91  The theatre's performance was breathtaking.   \n",
              "92          Her behaviour has been commendable.   \n",
              "93               The cheque was never received.   \n",
              "94           The aeroplane ✈️ took off on time.   \n",
              "95   She wears jewellery for special occasions.   \n",
              "\n",
              "                                    target_text  \n",
              "0       I color the center of my favorite book.  \n",
              "1               He is traveling to the theater.  \n",
              "2        I have an apartment near the elevator.  \n",
              "3        I have an apartment near the elevator.  \n",
              "4          The program will start at 6 o'clock.  \n",
              "..                                          ...  \n",
              "91  The theater's performance was breathtaking.  \n",
              "92           Her behavior has been commendable.  \n",
              "93                The check was never received.  \n",
              "94               The airplane took off on time.  \n",
              "95     She wears jewelry for special occasions.  \n",
              "\n",
              "[96 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file=r\"D:\\Data centr\\Exel_data\\int data\\CozmoX Assignment Dataset.csv\"\n",
        "data=pd.read_csv(file)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iShIWMC_IjJU",
        "outputId": "2536e4b9-2227-4d9a-bf83-b4993a30245d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 96 entries, 0 to 95\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   input_text   96 non-null     object\n",
            " 1   target_text  96 non-null     object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.6+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "tlZ1Sp5sIwve",
        "outputId": "a6cd5a77-86db-4200-8e0d-3c23404cc345"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "input_text     0\n",
              "target_text    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7dN5WXSGu2f"
      },
      "source": [
        "* Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "J8aDHh0EJV-k"
      },
      "outputs": [],
      "source": [
        "import unicodedata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IYMW8Gm7G7qD"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "  text=unicodedata.normalize(\"NFKC\", text) # Normalize the char\n",
        "  text=text.lower()\n",
        "  text=re.sub(r\"[^\\w\\s]\", \"\", text)  # remove special characters & Emojis\n",
        "  text=re.sub(r\"\\s+\", \" \", text)  # remove extra spaces\n",
        "  return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX7FctnWLAcR"
      },
      "source": [
        "Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fzq2d-IFKVPd"
      },
      "outputs": [],
      "source": [
        "data[\"input_text\"] = data[\"input_text\"].apply(clean_text)\n",
        "data[\"target_text\"] = data[\"target_text\"].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb9bvYLjLEFD",
        "outputId": "2b0d5ef4-7395-4c50-9b6a-1a44ed24520c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                 input_text   \n",
            "0  i colour the centre of my favourite book  \\\n",
            "1           he is travelling to the theatre   \n",
            "2               i have a flat near the lift   \n",
            "3              i have a flat near the lift    \n",
            "4      the programme will start at 6 oclock   \n",
            "\n",
            "                              target_text  \n",
            "0  i color the center of my favorite book  \n",
            "1          he is traveling to the theater  \n",
            "2   i have an apartment near the elevator  \n",
            "3   i have an apartment near the elevator  \n",
            "4      the program will start at 6 oclock  \n"
          ]
        }
      ],
      "source": [
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibVmbRfULV6C",
        "outputId": "fa71cab4-e489-4482-d945-c79953468a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " saved\n"
          ]
        }
      ],
      "source": [
        "data.to_csv(\"processed_cozmoX.csv\", index=False)\n",
        "print(\"\\n saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LZ7GxY0PEes"
      },
      "source": [
        "# Model Selection- T5\n",
        "Pretrained on Text Transformation.\n",
        "\n",
        "Best for small dataset with accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YGyMCYZoPRlp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\himan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, TFAutoModelForSeq2SeqLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkZyZE_6Gza0"
      },
      "source": [
        "* Tokenization- breaking text into smaller units (tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWtWgCm68mpZ",
        "outputId": "a55cb2a5-ec3b-4e3d-cbf0-ecfe61763aaa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "tokanizer=T5Tokenizer.from_pretrained(\"t5-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p0p6YeXJ3Q_",
        "outputId": "2318753c-39a8-44dd-b923-3cc41df10e29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\himan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\himan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "model_t5=TFAutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BU6XScMR_0X_"
      },
      "outputs": [],
      "source": [
        "def tokenize_data(sentence):\n",
        "  input_text = \"translate UK to US: \" + sentence[\"input_text\"]  # Task prefix\n",
        "  target_text = sentence[\"target_text\"]\n",
        "\n",
        "  tokenized_inputs = tokanizer(input_text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"tf\")\n",
        "  tokenized_targets=tokanizer(target_text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"tf\")\n",
        "\n",
        "  return{\n",
        "      \"input_ids\": tokenized_inputs[\"input_ids\"][0],  # Extract tensors\n",
        "      \"attention_mask\": tokenized_inputs[\"attention_mask\"][0],\n",
        "      \"labels\": tokenized_targets[\"input_ids\"][0],\n",
        "      }\n",
        "\n",
        "token_dataset=data.apply(tokenize_data, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2ca7q-gVr8U"
      },
      "source": [
        "Convert the tokenized dataset to a TensorFlow dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "z1irxqIw_0NT"
      },
      "outputs": [],
      "source": [
        "def to_tf(tokenized_data):\n",
        "  input_ids=[]\n",
        "  attention_masks=[]\n",
        "  labels=[]\n",
        "\n",
        "  for item in tokenized_data:\n",
        "    input_ids.append(item[\"input_ids\"])\n",
        "    attention_masks.append(item[\"attention_mask\"])\n",
        "    labels.append(item[\"labels\"])\n",
        "\n",
        "  return tf.data.Dataset.from_tensor_slices(({\n",
        "      \"input_ids\": input_ids,\n",
        "      \"attention_mask\": attention_masks\n",
        "  },\n",
        "      tf.stack(labels)\n",
        "  ))\n",
        "  tf_dataset=to_tf(token_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-tfRDAqWYUj"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lQF-b-XIKnMD"
      },
      "outputs": [],
      "source": [
        "lr_sechedule=tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.9,\n",
        "    staircase=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yycGVc55Wxbp"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_sechedule)\n",
        "loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPEuvWo7Y8St",
        "outputId": "c515238c-2ca7-4bfb-d5d8-54b9b0cf8db8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: [12.706329]\n",
            "Loss: [2.2442045]\n",
            "Loss: [0.25050882]\n",
            "Loss: [0.3531435]\n",
            "Loss: [0.39835292]\n",
            "Loss: [0.24258265]\n",
            "Loss: [0.22039552]\n",
            "Loss: [0.25458455]\n",
            "Loss: [0.1920833]\n",
            "Loss: [0.11431481]\n",
            "Loss: [0.13166723]\n",
            "Loss: [0.0862973]\n",
            "Loss: [0.10901935]\n",
            "Loss: [0.11264656]\n",
            "Loss: [0.9105618]\n",
            "Loss: [0.17528506]\n",
            "Loss: [0.21915969]\n",
            "Loss: [0.24879193]\n",
            "Loss: [0.23987854]\n",
            "Loss: [0.20293619]\n",
            "Loss: [0.22588362]\n",
            "Loss: [0.23429261]\n",
            "Loss: [0.24289829]\n",
            "Loss: [0.19904365]\n",
            "Loss: [0.24879585]\n",
            "Loss: [0.16451147]\n",
            "Loss: [0.20556447]\n",
            "Loss: [0.1878223]\n",
            "Loss: [0.14254296]\n",
            "Loss: [0.10083942]\n",
            "Loss: [0.22203428]\n",
            "Loss: [0.14729905]\n",
            "Loss: [0.10394251]\n",
            "Loss: [0.1199896]\n",
            "Loss: [0.08560469]\n",
            "Loss: [0.08905366]\n",
            "Loss: [0.09182685]\n",
            "Loss: [0.12435038]\n",
            "Loss: [0.05666936]\n",
            "Loss: [0.09219187]\n",
            "Loss: [0.19628417]\n",
            "Loss: [0.07823987]\n",
            "Loss: [0.06094883]\n",
            "Loss: [0.10114169]\n",
            "Loss: [0.10299458]\n",
            "Loss: [0.05737923]\n",
            "Loss: [0.07074274]\n",
            "Loss: [0.05352058]\n",
            "Loss: [0.14460175]\n",
            "Loss: [0.04164637]\n",
            "Loss: [0.06234517]\n",
            "Loss: [0.04528929]\n",
            "Loss: [0.11718763]\n",
            "Loss: [0.06203755]\n",
            "Loss: [0.07486938]\n",
            "Loss: [0.13877676]\n",
            "Loss: [0.09436031]\n",
            "Loss: [0.08151836]\n",
            "Loss: [0.05770404]\n",
            "Loss: [0.09917235]\n",
            "Loss: [0.06630939]\n",
            "Loss: [0.07689647]\n",
            "Loss: [0.08475004]\n",
            "Loss: [0.10615241]\n",
            "Loss: [0.03883329]\n",
            "Loss: [0.0513659]\n",
            "Loss: [0.07393689]\n",
            "Loss: [0.07003224]\n",
            "Loss: [0.03092087]\n",
            "Loss: [0.08965725]\n",
            "Loss: [0.04318956]\n",
            "Loss: [0.02167677]\n",
            "Loss: [0.02580327]\n",
            "Loss: [0.07333791]\n",
            "Loss: [0.04031607]\n",
            "Loss: [0.05474849]\n",
            "Loss: [0.01347293]\n",
            "Loss: [0.01257582]\n",
            "Loss: [0.02608199]\n",
            "Loss: [0.04090111]\n",
            "Loss: [0.02141901]\n",
            "Loss: [0.11074247]\n",
            "Loss: [0.02061235]\n",
            "Loss: [0.04912418]\n",
            "Loss: [0.04789896]\n",
            "Loss: [0.05753131]\n",
            "Loss: [0.08318544]\n",
            "Loss: [0.07694468]\n",
            "Loss: [0.05460555]\n",
            "Loss: [0.07356551]\n",
            "Loss: [0.07215072]\n",
            "Loss: [0.06411338]\n",
            "Loss: [0.06139617]\n",
            "Loss: [0.04636005]\n",
            "Loss: [0.04164183]\n",
            "Loss: [0.0039993]\n",
            "Completed epoch 1\n",
            "Loss: [0.05525208]\n",
            "Loss: [0.00716397]\n",
            "Loss: [0.04111963]\n",
            "Loss: [0.02860859]\n",
            "Loss: [0.01733348]\n",
            "Loss: [0.01414954]\n",
            "Loss: [0.00849801]\n",
            "Loss: [0.05688848]\n",
            "Loss: [0.03063317]\n",
            "Loss: [0.00914859]\n",
            "Loss: [0.04379118]\n",
            "Loss: [0.003076]\n",
            "Loss: [0.00406805]\n",
            "Loss: [0.0042193]\n",
            "Loss: [0.00344544]\n",
            "Loss: [0.00386174]\n",
            "Loss: [0.07996634]\n",
            "Loss: [0.0082165]\n",
            "Loss: [0.01367801]\n",
            "Loss: [0.00121004]\n",
            "Loss: [0.00103297]\n",
            "Loss: [0.00086902]\n",
            "Loss: [0.00118667]\n",
            "Loss: [0.00143796]\n",
            "Loss: [0.03145595]\n",
            "Loss: [0.00352326]\n",
            "Loss: [0.00067754]\n",
            "Loss: [0.00764964]\n",
            "Loss: [0.00475267]\n",
            "Loss: [0.0025464]\n",
            "Loss: [0.00405383]\n",
            "Loss: [0.00128108]\n",
            "Loss: [0.01734992]\n",
            "Loss: [0.00213846]\n",
            "Loss: [0.00251075]\n",
            "Loss: [0.00038619]\n",
            "Loss: [0.00375123]\n",
            "Loss: [0.01775083]\n",
            "Loss: [0.00098677]\n",
            "Loss: [0.00112817]\n",
            "Loss: [0.00027155]\n",
            "Loss: [0.0004874]\n",
            "Loss: [0.00016592]\n",
            "Loss: [0.00560287]\n",
            "Loss: [0.00035744]\n",
            "Loss: [0.0005645]\n",
            "Loss: [0.00107007]\n",
            "Loss: [0.00066477]\n",
            "Loss: [0.00024606]\n",
            "Loss: [0.00054085]\n",
            "Loss: [0.0002982]\n",
            "Loss: [0.00076027]\n",
            "Loss: [0.00018753]\n",
            "Loss: [0.00044234]\n",
            "Loss: [0.00050993]\n",
            "Loss: [0.00971151]\n",
            "Loss: [0.00015625]\n",
            "Loss: [0.00029048]\n",
            "Loss: [0.00058248]\n",
            "Loss: [0.00022647]\n",
            "Loss: [0.00038664]\n",
            "Loss: [8.398747e-05]\n",
            "Loss: [0.00017961]\n",
            "Loss: [0.00034491]\n",
            "Loss: [0.00019317]\n",
            "Loss: [0.01501836]\n",
            "Loss: [0.00012315]\n",
            "Loss: [0.00083732]\n",
            "Loss: [9.577474e-05]\n",
            "Loss: [0.00057797]\n",
            "Loss: [0.00030721]\n",
            "Loss: [0.00040125]\n",
            "Loss: [0.00010657]\n",
            "Loss: [0.00042811]\n",
            "Loss: [0.00026029]\n",
            "Loss: [0.00023374]\n",
            "Loss: [9.379143e-05]\n",
            "Loss: [0.00081295]\n",
            "Loss: [0.00285808]\n",
            "Loss: [0.00094798]\n",
            "Loss: [0.00012822]\n",
            "Loss: [0.0004169]\n",
            "Loss: [0.0001087]\n",
            "Loss: [0.04281576]\n",
            "Loss: [0.00204673]\n",
            "Loss: [0.00020856]\n",
            "Loss: [0.00024809]\n",
            "Loss: [0.0001297]\n",
            "Loss: [0.00889342]\n",
            "Loss: [0.00021283]\n",
            "Loss: [0.00042088]\n",
            "Loss: [0.03213834]\n",
            "Loss: [0.00048083]\n",
            "Loss: [0.00023671]\n",
            "Loss: [0.00062877]\n",
            "Loss: [0.10821582]\n",
            "Completed epoch 2\n",
            "Loss: [0.00205255]\n",
            "Loss: [0.00087503]\n",
            "Loss: [0.00207374]\n",
            "Loss: [0.00191408]\n",
            "Loss: [0.00055375]\n",
            "Loss: [0.00435129]\n",
            "Loss: [0.02005215]\n",
            "Loss: [0.05617674]\n",
            "Loss: [0.00275252]\n",
            "Loss: [0.00143094]\n",
            "Loss: [0.00079917]\n",
            "Loss: [0.00183754]\n",
            "Loss: [0.0006215]\n",
            "Loss: [0.00081585]\n",
            "Loss: [0.00055151]\n",
            "Loss: [0.04842984]\n",
            "Loss: [0.03381586]\n",
            "Loss: [0.00122175]\n",
            "Loss: [0.00419788]\n",
            "Loss: [0.00143482]\n",
            "Loss: [0.00549162]\n",
            "Loss: [0.02754367]\n",
            "Loss: [0.03226985]\n",
            "Loss: [0.00496472]\n",
            "Loss: [0.04088151]\n",
            "Loss: [0.00336216]\n",
            "Loss: [0.00860151]\n",
            "Loss: [0.0093164]\n",
            "Loss: [0.00530698]\n",
            "Loss: [0.00207922]\n",
            "Loss: [0.01548837]\n",
            "Loss: [0.0307084]\n",
            "Loss: [0.00064132]\n",
            "Loss: [0.00209736]\n",
            "Loss: [0.00264901]\n",
            "Loss: [0.00096053]\n",
            "Loss: [0.00291053]\n",
            "Loss: [0.00433633]\n",
            "Loss: [0.00138259]\n",
            "Loss: [0.00265192]\n",
            "Loss: [0.00017891]\n",
            "Loss: [0.0003675]\n",
            "Loss: [0.0008623]\n",
            "Loss: [0.05077665]\n",
            "Loss: [0.00057337]\n",
            "Loss: [0.00057834]\n",
            "Loss: [0.01589494]\n",
            "Loss: [0.00123862]\n",
            "Loss: [0.00097166]\n",
            "Loss: [0.0122832]\n",
            "Loss: [0.00092815]\n",
            "Loss: [0.0009918]\n",
            "Loss: [0.00039582]\n",
            "Loss: [0.00204717]\n",
            "Loss: [0.00056833]\n",
            "Loss: [0.01071485]\n",
            "Loss: [0.00039032]\n",
            "Loss: [0.00029484]\n",
            "Loss: [0.00074419]\n",
            "Loss: [0.00141458]\n",
            "Loss: [0.00077173]\n",
            "Loss: [0.00013999]\n",
            "Loss: [0.00227756]\n",
            "Loss: [0.00117274]\n",
            "Loss: [0.00049063]\n",
            "Loss: [0.10066211]\n",
            "Loss: [0.00025408]\n",
            "Loss: [0.00137089]\n",
            "Loss: [0.00028978]\n",
            "Loss: [0.0037205]\n",
            "Loss: [0.00043657]\n",
            "Loss: [0.00107483]\n",
            "Loss: [0.00024346]\n",
            "Loss: [0.00048023]\n",
            "Loss: [0.00119597]\n",
            "Loss: [0.00049268]\n",
            "Loss: [0.00015489]\n",
            "Loss: [0.00179646]\n",
            "Loss: [0.00022824]\n",
            "Loss: [0.00026998]\n",
            "Loss: [0.0001416]\n",
            "Loss: [0.00023277]\n",
            "Loss: [0.00017023]\n",
            "Loss: [0.01708498]\n",
            "Loss: [0.00079113]\n",
            "Loss: [0.00027478]\n",
            "Loss: [0.00023299]\n",
            "Loss: [0.000108]\n",
            "Loss: [0.01360249]\n",
            "Loss: [0.00097061]\n",
            "Loss: [0.00024895]\n",
            "Loss: [0.00536212]\n",
            "Loss: [0.00026141]\n",
            "Loss: [0.00017035]\n",
            "Loss: [0.00017071]\n",
            "Loss: [0.03856155]\n",
            "Completed epoch 3\n"
          ]
        }
      ],
      "source": [
        "epochs=3\n",
        "tf_dataset=to_tf(token_dataset).batch(1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for batch in tf_dataset:\n",
        "    inputs, labels = batch\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Forward pass\n",
        "      outputs = model_t5(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], labels=labels)\n",
        "      loss = outputs.loss\n",
        "\n",
        "      # Backward pass\n",
        "      gradients = tape.gradient(loss, model_t5.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(gradients, model_t5.trainable_variables))\n",
        "\n",
        "      print(f\"Loss: {loss.numpy()}\")\n",
        "\n",
        "  print(f\"Completed epoch {epoch + 1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avXdt5X5WeMN"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from evaluate import load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Azd_yv30_0GM"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "To be able to use evaluate-metric/rouge, you need to install the following dependencies['rouge_score'] using 'pip install rouge_score' for instance'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m bleu_metric \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m rouge_metric \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrouge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\himan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\evaluate\\loading.py:748\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a [`~evaluate.EvaluationModule`].\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    747\u001b[0m download_mode \u001b[38;5;241m=\u001b[39m DownloadMode(download_mode \u001b[38;5;129;01mor\u001b[39;00m DownloadMode\u001b[38;5;241m.\u001b[39mREUSE_DATASET_IF_EXISTS)\n\u001b[1;32m--> 748\u001b[0m evaluation_module \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m evaluation_cls \u001b[38;5;241m=\u001b[39m import_main_class(evaluation_module\u001b[38;5;241m.\u001b[39mmodule_path)\n\u001b[0;32m    752\u001b[0m evaluation_instance \u001b[38;5;241m=\u001b[39m evaluation_cls(\n\u001b[0;32m    753\u001b[0m     config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[0;32m    754\u001b[0m     process_id\u001b[38;5;241m=\u001b[39mprocess_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs,\n\u001b[0;32m    761\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\himan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\evaluate\\loading.py:680\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[1;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[0;32m    678\u001b[0m                 \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, (\u001b[38;5;167;01mConnectionError\u001b[39;00m, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m)):\n\u001b[1;32m--> 680\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    682\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a module script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    683\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist on the Hugging Face Hub either.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    684\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\himan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\evaluate\\loading.py:639\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[1;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m current_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomparison\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeasurement\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubEvaluationModuleFactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluate-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcurrent_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 639\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\himan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\evaluate\\loading.py:489\u001b[0m, in \u001b[0;36mHubEvaluationModuleFactory.get_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    488\u001b[0m imports \u001b[38;5;241m=\u001b[39m get_imports(local_path)\n\u001b[1;32m--> 489\u001b[0m local_imports \u001b[38;5;241m=\u001b[39m \u001b[43m_download_additional_modules\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_hub_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimports\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;66;03m# copy the script and the files in an importable directory\u001b[39;00m\n\u001b[0;32m    496\u001b[0m dynamic_modules_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_modules_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_modules_path \u001b[38;5;28;01melse\u001b[39;00m init_dynamic_modules()\n",
            "File \u001b[1;32mc:\\Users\\himan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\evaluate\\loading.py:265\u001b[0m, in \u001b[0;36m_download_additional_modules\u001b[1;34m(name, base_path, imports, download_config)\u001b[0m\n\u001b[0;32m    263\u001b[0m         needs_to_be_installed\u001b[38;5;241m.\u001b[39madd((library_import_name, library_import_path))\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_to_be_installed:\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo be able to use \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, you need to install the following dependencies\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[lib_name\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mlib_name,\u001b[38;5;250m \u001b[39mlib_path\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mneeds_to_be_installed]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([lib_path\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mlib_name,\u001b[38;5;250m \u001b[39mlib_path\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mneeds_to_be_installed])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for instance\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    269\u001b[0m     )\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m local_imports\n",
            "\u001b[1;31mImportError\u001b[0m: To be able to use evaluate-metric/rouge, you need to install the following dependencies['rouge_score'] using 'pip install rouge_score' for instance'"
          ]
        }
      ],
      "source": [
        "bleu_metric = load(\"bleu\")\n",
        "rouge_metric = load(\"rouge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs9chnTgORCo"
      },
      "outputs": [],
      "source": [
        "epochs = 3\n",
        "batch_size = 1\n",
        "tf_dataset = to_tf(token_dataset).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_IK6GgXWp4E"
      },
      "source": [
        "# Graph Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbVIKw89Wmbt"
      },
      "source": [
        "# Model Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqK4xXMS_0C4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
