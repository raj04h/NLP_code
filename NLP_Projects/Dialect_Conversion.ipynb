{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJpKaj1YGQZF"
      },
      "source": [
        "# Dialect Conversion Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oUXJxeBGY70"
      },
      "source": [
        "convert text between UK and US dialects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn7KN3aDGhUe"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3rPmdS0RC4S",
        "outputId": "7557a74f-3544-4709-af1c-f212f5e57ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (4.42.4)\n",
            "Requirement already satisfied: datasets in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (19.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ex_Z4yNGmfE"
      },
      "source": [
        "* Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b-vCUhs5G6_C"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UHbpnHnlHTNd",
        "outputId": "ace93587-7827-4431-812f-68dfd7a1d64f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I CoLoUr üé® the centre of my favourite book.</td>\n",
              "      <td>I color the center of my favorite book.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>He is travelling ‚úàÔ∏è to the THEATRE.</td>\n",
              "      <td>He is traveling to the theater.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I have a flat near the lift.</td>\n",
              "      <td>I have an apartment near the elevator.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I have a flat near the lift.</td>\n",
              "      <td>I have an apartment near the elevator.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The PROGRAMME üóìÔ∏è will start at 6 O'CLOCK.</td>\n",
              "      <td>The program will start at 6 o'clock.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>The theatre's performance was breathtaking.</td>\n",
              "      <td>The theater's performance was breathtaking.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>Her behaviour has been commendable.</td>\n",
              "      <td>Her behavior has been commendable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>The cheque was never received.</td>\n",
              "      <td>The check was never received.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>The aeroplane ‚úàÔ∏è took off on time.</td>\n",
              "      <td>The airplane took off on time.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>She wears jewellery for special occasions.</td>\n",
              "      <td>She wears jewelry for special occasions.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     input_text  \\\n",
              "0   I CoLoUr üé® the centre of my favourite book.   \n",
              "1           He is travelling ‚úàÔ∏è to the THEATRE.   \n",
              "2                  I have a flat near the lift.   \n",
              "3                 I have a flat near the lift.    \n",
              "4     The PROGRAMME üóìÔ∏è will start at 6 O'CLOCK.   \n",
              "..                                          ...   \n",
              "91  The theatre's performance was breathtaking.   \n",
              "92          Her behaviour has been commendable.   \n",
              "93               The cheque was never received.   \n",
              "94           The aeroplane ‚úàÔ∏è took off on time.   \n",
              "95   She wears jewellery for special occasions.   \n",
              "\n",
              "                                    target_text  \n",
              "0       I color the center of my favorite book.  \n",
              "1               He is traveling to the theater.  \n",
              "2        I have an apartment near the elevator.  \n",
              "3        I have an apartment near the elevator.  \n",
              "4          The program will start at 6 o'clock.  \n",
              "..                                          ...  \n",
              "91  The theater's performance was breathtaking.  \n",
              "92           Her behavior has been commendable.  \n",
              "93                The check was never received.  \n",
              "94               The airplane took off on time.  \n",
              "95     She wears jewelry for special occasions.  \n",
              "\n",
              "[96 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file=r\"D:\\Data centr\\Exel_data\\int data\\CozmoX Assignment Dataset.csv\"\n",
        "data=pd.read_csv(file)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iShIWMC_IjJU",
        "outputId": "2536e4b9-2227-4d9a-bf83-b4993a30245d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 96 entries, 0 to 95\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   input_text   96 non-null     object\n",
            " 1   target_text  96 non-null     object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.6+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "tlZ1Sp5sIwve",
        "outputId": "a6cd5a77-86db-4200-8e0d-3c23404cc345"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "input_text     0\n",
              "target_text    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7dN5WXSGu2f"
      },
      "source": [
        "* Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "J8aDHh0EJV-k"
      },
      "outputs": [],
      "source": [
        "import unicodedata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IYMW8Gm7G7qD"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "  text=unicodedata.normalize(\"NFKC\", text) # Normalize the char\n",
        "  text=text.lower()\n",
        "  text=re.sub(r\"[^\\w\\s]\", \"\", text)  # remove special characters & Emojis\n",
        "  text=re.sub(r\"\\s+\", \" \", text)  # remove extra spaces\n",
        "  return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX7FctnWLAcR"
      },
      "source": [
        "Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fzq2d-IFKVPd"
      },
      "outputs": [],
      "source": [
        "data[\"input_text\"] = data[\"input_text\"].apply(clean_text)\n",
        "data[\"target_text\"] = data[\"target_text\"].apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb9bvYLjLEFD",
        "outputId": "2b0d5ef4-7395-4c50-9b6a-1a44ed24520c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                 input_text  \\\n",
            "0  i colour the centre of my favourite book   \n",
            "1           he is travelling to the theatre   \n",
            "2               i have a flat near the lift   \n",
            "3              i have a flat near the lift    \n",
            "4      the programme will start at 6 oclock   \n",
            "\n",
            "                              target_text  \n",
            "0  i color the center of my favorite book  \n",
            "1          he is traveling to the theater  \n",
            "2   i have an apartment near the elevator  \n",
            "3   i have an apartment near the elevator  \n",
            "4      the program will start at 6 oclock  \n"
          ]
        }
      ],
      "source": [
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibVmbRfULV6C",
        "outputId": "fa71cab4-e489-4482-d945-c79953468a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " saved\n"
          ]
        }
      ],
      "source": [
        "data.to_csv(\"processed_cozmoX.csv\", index=False)\n",
        "print(\"\\n saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LZ7GxY0PEes"
      },
      "source": [
        "# Model Selection- T5\n",
        "Pretrained on Text Transformation.\n",
        "\n",
        "Best for small dataset with accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YGyMCYZoPRlp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, TFAutoModelForSeq2SeqLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkZyZE_6Gza0"
      },
      "source": [
        "* Tokenization- breaking text into smaller units (tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWtWgCm68mpZ",
        "outputId": "a55cb2a5-ec3b-4e3d-cbf0-ecfe61763aaa"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "\nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokanizer\u001b[38;5;241m=\u001b[39m\u001b[43mT5Tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\import_utils.py:1507\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1507\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\import_utils.py:1495\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1493\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m-> 1495\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
            "\u001b[1;31mImportError\u001b[0m: \nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
          ]
        }
      ],
      "source": [
        "tokanizer=T5Tokenizer.from_pretrained(\"t5-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p0p6YeXJ3Q_",
        "outputId": "2318753c-39a8-44dd-b923-3cc41df10e29"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8b389e04d7d45379c703eb2cf3bafcc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\himan\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\himan\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.models.t5.modeling_tf_t5 because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\import_utils.py:1567\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\himan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\t5\\modeling_tf_t5.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf2xla\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxla\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_slice\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     TFBaseModelOutput,\n\u001b[0;32m     33\u001b[0m     TFBaseModelOutputWithPastAndCrossAttentions,\n\u001b[0;32m     34\u001b[0m     TFSeq2SeqLMOutput,\n\u001b[0;32m     35\u001b[0m     TFSeq2SeqModelOutput,\n\u001b[0;32m     36\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n",
            "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_t5\u001b[38;5;241m=\u001b[39m\u001b[43mTFAutoModelForSeq2SeqLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mt5-small\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\auto\\auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    560\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    561\u001b[0m     )\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m--> 563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\auto\\auto_factory.py:384\u001b[0m, in \u001b[0;36m_get_model_class\u001b[1;34m(config, model_mapping)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_model_class\u001b[39m(config, model_mapping):\n\u001b[1;32m--> 384\u001b[0m     supported_models \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(supported_models, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m supported_models\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\auto\\auto_factory.py:735\u001b[0m, in \u001b[0;36m_LazyAutoMapping.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping:\n\u001b[0;32m    734\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping[model_type]\n\u001b[1;32m--> 735\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_attr_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;66;03m# Maybe there was several model types associated with this config.\u001b[39;00m\n\u001b[0;32m    738\u001b[0m model_types \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m==\u001b[39m key\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\auto\\auto_factory.py:749\u001b[0m, in \u001b[0;36m_LazyAutoMapping._load_attr_from_module\u001b[1;34m(self, model_type, attr)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[module_name] \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetattribute_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\auto\\auto_factory.py:693\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[1;34m(module, attr)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attr, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m attr)\n\u001b[1;32m--> 693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, attr)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;66;03m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;66;03m# object at the top level.\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\import_utils.py:1557\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1555\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1557\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1558\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\import_utils.py:1569\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1570\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1571\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1572\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.t5.modeling_tf_t5 because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
          ]
        }
      ],
      "source": [
        "model_t5=TFAutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU6XScMR_0X_"
      },
      "outputs": [],
      "source": [
        "def tokenize_data(sentence):\n",
        "  input_text = \"translate UK to US: \" + sentence[\"input_text\"]  # Task prefix\n",
        "  target_text = sentence[\"target_text\"]\n",
        "\n",
        "  tokenized_inputs = tokanizer(input_text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"tf\")\n",
        "  tokenized_targets=tokanizer(target_text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"tf\")\n",
        "\n",
        "  return{\n",
        "      \"input_ids\": tokenized_inputs[\"input_ids\"][0],  # Extract tensors\n",
        "      \"attention_mask\": tokenized_inputs[\"attention_mask\"][0],\n",
        "      \"labels\": tokenized_targets[\"input_ids\"][0],\n",
        "      }\n",
        "\n",
        "token_dataset=data.apply(tokenize_data, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2ca7q-gVr8U"
      },
      "source": [
        "Convert the tokenized dataset to a TensorFlow dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1irxqIw_0NT"
      },
      "outputs": [],
      "source": [
        "def to_tf(tokenized_data):\n",
        "  input_ids=[]\n",
        "  attention_masks=[]\n",
        "  labels=[]\n",
        "\n",
        "  for item in tokenized_data:\n",
        "    input_ids.append(item[\"input_ids\"])\n",
        "    attention_masks.append(item[\"attention_mask\"])\n",
        "    labels.append(item[\"labels\"])\n",
        "\n",
        "  return tf.data.Dataset.from_tensor_slices(({\n",
        "      \"input_ids\": input_ids,\n",
        "      \"attention_mask\": attention_masks\n",
        "  },\n",
        "      tf.stack(labels)\n",
        "  ))\n",
        "  tf_dataset=to_tf(token_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-tfRDAqWYUj"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQF-b-XIKnMD"
      },
      "outputs": [],
      "source": [
        "lr_sechedule=tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.9,\n",
        "    staircase=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yycGVc55Wxbp"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_sechedule)\n",
        "loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPEuvWo7Y8St",
        "outputId": "c515238c-2ca7-4bfb-d5d8-54b9b0cf8db8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: [12.706329]\n",
            "Loss: [2.2442951]\n",
            "Loss: [0.2505015]\n",
            "Loss: [0.3531171]\n",
            "Loss: [0.3986079]\n",
            "Loss: [0.24281038]\n",
            "Loss: [0.22058555]\n",
            "Loss: [0.25443977]\n",
            "Loss: [0.19203994]\n",
            "Loss: [0.1145226]\n",
            "Loss: [0.1316802]\n",
            "Loss: [0.08652504]\n",
            "Loss: [0.10950559]\n",
            "Loss: [0.112593]\n",
            "Loss: [0.93117225]\n",
            "Loss: [0.17465067]\n",
            "Loss: [0.21873325]\n",
            "Loss: [0.24966328]\n",
            "Loss: [0.23980461]\n",
            "Loss: [0.20394622]\n",
            "Loss: [0.22640981]\n",
            "Loss: [0.2358234]\n",
            "Loss: [0.24417378]\n",
            "Loss: [0.20024405]\n",
            "Loss: [0.24859968]\n",
            "Loss: [0.16591159]\n",
            "Loss: [0.20332566]\n",
            "Loss: [0.18894415]\n",
            "Loss: [0.14160864]\n",
            "Loss: [0.10031667]\n",
            "Loss: [0.22113289]\n",
            "Loss: [0.14782056]\n",
            "Loss: [0.10265744]\n",
            "Loss: [0.11954636]\n",
            "Loss: [0.08252819]\n",
            "Loss: [0.08897171]\n",
            "Loss: [0.09104161]\n",
            "Loss: [0.12273808]\n",
            "Loss: [0.05601484]\n",
            "Loss: [0.09164664]\n",
            "Loss: [0.20164451]\n",
            "Loss: [0.07710923]\n",
            "Loss: [0.06035168]\n",
            "Loss: [0.10468307]\n",
            "Loss: [0.10275453]\n",
            "Loss: [0.05793048]\n",
            "Loss: [0.07010919]\n",
            "Loss: [0.05244632]\n",
            "Loss: [0.15660946]\n",
            "Loss: [0.04061674]\n",
            "Loss: [0.06268049]\n",
            "Loss: [0.04417473]\n",
            "Loss: [0.11729388]\n",
            "Loss: [0.06089301]\n",
            "Loss: [0.07004327]\n",
            "Loss: [0.15660356]\n",
            "Loss: [0.09444357]\n",
            "Loss: [0.07656255]\n",
            "Loss: [0.06275485]\n",
            "Loss: [0.11410353]\n",
            "Loss: [0.06899944]\n",
            "Loss: [0.08021443]\n",
            "Loss: [0.09296202]\n",
            "Loss: [0.11284883]\n",
            "Loss: [0.04292681]\n",
            "Loss: [0.06019932]\n",
            "Loss: [0.08216301]\n",
            "Loss: [0.08077884]\n",
            "Loss: [0.03500898]\n",
            "Loss: [0.05273182]\n",
            "Loss: [0.03055697]\n",
            "Loss: [0.02329543]\n",
            "Loss: [0.02312613]\n",
            "Loss: [0.06603025]\n",
            "Loss: [0.04178066]\n",
            "Loss: [0.04055886]\n",
            "Loss: [0.07267059]\n",
            "Loss: [0.07072774]\n",
            "Loss: [0.03409391]\n",
            "Loss: [0.04613172]\n",
            "Loss: [0.06105656]\n",
            "Loss: [0.03784215]\n",
            "Loss: [0.05976328]\n",
            "Loss: [0.05166335]\n",
            "Loss: [0.04857131]\n",
            "Loss: [0.07523257]\n",
            "Loss: [0.07682627]\n",
            "Loss: [0.07389452]\n",
            "Loss: [0.03571836]\n",
            "Loss: [0.05397348]\n",
            "Loss: [0.06060031]\n",
            "Loss: [0.04339726]\n",
            "Loss: [0.07729913]\n",
            "Loss: [0.04961064]\n",
            "Loss: [0.07215691]\n",
            "Loss: [0.00286818]\n",
            "Completed epoch 1\n",
            "Loss: [0.06704637]\n",
            "Loss: [0.01457378]\n",
            "Loss: [0.04536843]\n",
            "Loss: [0.03253913]\n",
            "Loss: [0.04537767]\n",
            "Loss: [0.00768712]\n",
            "Loss: [0.01673647]\n",
            "Loss: [0.05468132]\n",
            "Loss: [0.03397704]\n",
            "Loss: [0.00181709]\n",
            "Loss: [0.01839128]\n",
            "Loss: [0.00313543]\n",
            "Loss: [0.00813568]\n",
            "Loss: [0.00429742]\n",
            "Loss: [0.01383533]\n",
            "Loss: [0.00572965]\n",
            "Loss: [0.07110211]\n",
            "Loss: [0.0047819]\n",
            "Loss: [0.01290119]\n",
            "Loss: [0.00378317]\n",
            "Loss: [0.00332055]\n",
            "Loss: [0.01270631]\n",
            "Loss: [0.00101708]\n",
            "Loss: [0.00189079]\n",
            "Loss: [0.03547399]\n",
            "Loss: [0.00287461]\n",
            "Loss: [0.00103755]\n",
            "Loss: [0.00146044]\n",
            "Loss: [0.00507218]\n",
            "Loss: [0.00208296]\n",
            "Loss: [0.01319683]\n",
            "Loss: [0.00338492]\n",
            "Loss: [0.0029966]\n",
            "Loss: [0.00519281]\n",
            "Loss: [0.00432255]\n",
            "Loss: [0.00041772]\n",
            "Loss: [0.0067674]\n",
            "Loss: [0.00173751]\n",
            "Loss: [0.00282022]\n",
            "Loss: [0.00431825]\n",
            "Loss: [0.00068497]\n",
            "Loss: [0.00034045]\n",
            "Loss: [0.00049703]\n",
            "Loss: [0.00309794]\n",
            "Loss: [0.00156699]\n",
            "Loss: [0.00059737]\n",
            "Loss: [0.00102761]\n",
            "Loss: [0.0013857]\n",
            "Loss: [0.00023855]\n",
            "Loss: [0.00053393]\n",
            "Loss: [0.00050768]\n",
            "Loss: [0.0010549]\n",
            "Loss: [0.00048989]\n",
            "Loss: [0.0008475]\n",
            "Loss: [0.00024177]\n",
            "Loss: [0.02286235]\n",
            "Loss: [0.00012761]\n",
            "Loss: [0.00023878]\n",
            "Loss: [0.00100695]\n",
            "Loss: [0.00032218]\n",
            "Loss: [0.0005691]\n",
            "Loss: [0.00011843]\n",
            "Loss: [0.00079929]\n",
            "Loss: [0.00220431]\n",
            "Loss: [0.00016488]\n",
            "Loss: [0.00054052]\n",
            "Loss: [0.00013298]\n",
            "Loss: [0.00095897]\n",
            "Loss: [0.0001214]\n",
            "Loss: [0.00110007]\n",
            "Loss: [0.00056834]\n",
            "Loss: [0.00040527]\n",
            "Loss: [0.00011734]\n",
            "Loss: [0.0007407]\n",
            "Loss: [0.00047235]\n",
            "Loss: [0.00041804]\n",
            "Loss: [0.00010081]\n",
            "Loss: [0.00017854]\n",
            "Loss: [0.00018868]\n",
            "Loss: [0.00074749]\n",
            "Loss: [0.00011438]\n",
            "Loss: [0.00244728]\n",
            "Loss: [5.6538283e-05]\n",
            "Loss: [0.00076985]\n",
            "Loss: [0.00021396]\n",
            "Loss: [0.00020001]\n",
            "Loss: [0.00011422]\n",
            "Loss: [7.586786e-05]\n",
            "Loss: [0.00116783]\n",
            "Loss: [8.9597845e-05]\n",
            "Loss: [0.0001641]\n",
            "Loss: [0.00053914]\n",
            "Loss: [0.00031414]\n",
            "Loss: [0.00014006]\n",
            "Loss: [0.00019848]\n",
            "Loss: [0.0002747]\n",
            "Completed epoch 2\n",
            "Loss: [0.00148519]\n",
            "Loss: [0.00051929]\n",
            "Loss: [0.00223505]\n",
            "Loss: [0.00179629]\n",
            "Loss: [0.0002567]\n",
            "Loss: [0.00113971]\n",
            "Loss: [0.00035906]\n",
            "Loss: [0.05438131]\n",
            "Loss: [0.00030345]\n",
            "Loss: [7.1332935e-05]\n",
            "Loss: [0.0001218]\n",
            "Loss: [0.00117237]\n",
            "Loss: [0.00028884]\n",
            "Loss: [0.00041117]\n",
            "Loss: [8.805824e-05]\n",
            "Loss: [0.0002428]\n",
            "Loss: [0.03486264]\n",
            "Loss: [0.00029817]\n",
            "Loss: [0.00038019]\n",
            "Loss: [0.00031768]\n",
            "Loss: [0.00014342]\n",
            "Loss: [0.00020518]\n",
            "Loss: [0.00020748]\n",
            "Loss: [0.00027377]\n",
            "Loss: [0.08560815]\n",
            "Loss: [0.00062515]\n",
            "Loss: [0.00017977]\n",
            "Loss: [0.02058447]\n",
            "Loss: [0.00128866]\n",
            "Loss: [0.00026745]\n",
            "Loss: [0.00102948]\n",
            "Loss: [0.00049917]\n",
            "Loss: [0.00022468]\n",
            "Loss: [0.00262455]\n",
            "Loss: [0.00036211]\n",
            "Loss: [0.0002444]\n",
            "Loss: [0.00141942]\n",
            "Loss: [0.00047773]\n",
            "Loss: [0.00022151]\n",
            "Loss: [0.00045313]\n",
            "Loss: [0.00013196]\n",
            "Loss: [0.00029481]\n",
            "Loss: [0.00010405]\n",
            "Loss: [0.00103687]\n",
            "Loss: [0.00039419]\n",
            "Loss: [0.00027216]\n",
            "Loss: [0.00051579]\n",
            "Loss: [0.00023808]\n",
            "Loss: [0.0001086]\n",
            "Loss: [0.00023461]\n",
            "Loss: [0.00026541]\n",
            "Loss: [0.00019871]\n",
            "Loss: [0.00015095]\n",
            "Loss: [0.00042204]\n",
            "Loss: [0.0001881]\n",
            "Loss: [0.00204906]\n",
            "Loss: [0.00010583]\n",
            "Loss: [0.00016377]\n",
            "Loss: [0.00030366]\n",
            "Loss: [0.00016612]\n",
            "Loss: [0.0002969]\n",
            "Loss: [0.00015504]\n",
            "Loss: [0.0002427]\n",
            "Loss: [0.00030911]\n",
            "Loss: [0.00012251]\n",
            "Loss: [0.00035275]\n",
            "Loss: [9.066569e-05]\n",
            "Loss: [0.00053734]\n",
            "Loss: [0.00018981]\n",
            "Loss: [0.00032129]\n",
            "Loss: [0.00027338]\n",
            "Loss: [0.0002057]\n",
            "Loss: [0.00012429]\n",
            "Loss: [0.00025352]\n",
            "Loss: [0.00043792]\n",
            "Loss: [0.00019635]\n",
            "Loss: [0.00019615]\n",
            "Loss: [0.00011557]\n",
            "Loss: [5.6390134e-05]\n",
            "Loss: [0.00042945]\n",
            "Loss: [0.00014615]\n",
            "Loss: [0.00019209]\n",
            "Loss: [0.00112488]\n",
            "Loss: [0.00031615]\n",
            "Loss: [0.00012784]\n",
            "Loss: [8.912948e-05]\n",
            "Loss: [7.6394455e-05]\n",
            "Loss: [6.0558334e-05]\n",
            "Loss: [0.00043434]\n",
            "Loss: [8.488336e-05]\n",
            "Loss: [0.00012534]\n",
            "Loss: [0.00033422]\n",
            "Loss: [0.00022353]\n",
            "Loss: [9.931163e-05]\n",
            "Loss: [0.00018584]\n",
            "Loss: [0.00013777]\n",
            "Completed epoch 3\n"
          ]
        }
      ],
      "source": [
        "epochs=3\n",
        "tf_dataset=to_tf(token_dataset).batch(1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for batch in tf_dataset:\n",
        "    inputs, labels = batch\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Forward pass\n",
        "      outputs = model_t5(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], labels=labels)\n",
        "      loss = outputs.loss\n",
        "\n",
        "      # Backward pass\n",
        "      gradients = tape.gradient(loss, model_t5.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(gradients, model_t5.trainable_variables))\n",
        "\n",
        "      print(f\"Loss: {loss.numpy()}\")\n",
        "\n",
        "  print(f\"Completed epoch {epoch + 1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avXdt5X5WeMN"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'load_metric' from 'datasets' (c:\\Users\\himan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_metric\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'load_metric' from 'datasets' (c:\\Users\\himan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\__init__.py)"
          ]
        }
      ],
      "source": [
        "from datasets import load_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Azd_yv30_0GM"
      },
      "outputs": [],
      "source": [
        "bleu_matric=load_metric(\"bleu\")\n",
        "rouge_matric=load_metric(\"rouge\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4Oi4PSBWi08"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Hs9chnTgORCo"
      },
      "outputs": [],
      "source": [
        "epochs = 3\n",
        "batch_size = 1\n",
        "tf_dataset = to_tf(token_dataset).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_IK6GgXWp4E"
      },
      "source": [
        "# Graph Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbVIKw89Wmbt"
      },
      "source": [
        "# Model Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HqK4xXMS_0C4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dWLZvl6b_0AA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_GEv2wOK_z5e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
